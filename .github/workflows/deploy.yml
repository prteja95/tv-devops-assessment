name: CI/CD Deploy to AWS ECS

on:
  push:
    branches: [main]

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  APP_REPO_NAME: ${{ vars.APP_REPO_NAME }}
  APP_CLUSTER_NAME: ${{ vars.APP_CLUSTER_NAME }}
  APP_IMAGE_TAG: ${{ vars.APP_IMAGE_TAG }}
  CONTAINER_PORT: ${{ vars.CONTAINER_PORT }}
  ALB_PORT: ${{ vars.ALB_PORT }}
  DESIRED_TASKS: ${{ vars.DESIRED_TASKS }}
  ALB_ALLOWED_CIDRS: ${{ vars.ALB_ALLOWED_CIDRS }}
  SG_EGRESS_CIDRS: ${{ vars.SG_EGRESS_CIDRS }}
  ECS_CPU: ${{ vars.ECS_CPU }}
  ECS_MEMORY: ${{ vars.ECS_MEMORY }}
  LOG_RETENTION_DAYS: ${{ vars.LOG_RETENTION_DAYS }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: production

    steps:
      # Step 1: Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2: Clean CIDR blocks
      - name: Clean CIDR blocks
        id: clean-cidr
        run: |
          echo "CUSTOM_VPC_CIDR=${VARS_CUSTOM_VPC_CIDR//[$'\t\r\n ']}" >> $GITHUB_ENV
          echo "PUBLIC_SUBNET_CIDR_A=${VARS_PUBLIC_SUBNET_CIDR_A//[$'\t\r\n ']}" >> $GITHUB_ENV
          echo "PUBLIC_SUBNET_CIDR_B=${VARS_PUBLIC_SUBNET_CIDR_B//[$'\t\r\n ']}" >> $GITHUB_ENV
          echo "PRIVATE_SUBNET_CIDR_A=${VARS_PRIVATE_SUBNET_CIDR_A//[$'\t\r\n ']}" >> $GITHUB_ENV
          echo "PRIVATE_SUBNET_CIDR_B=${VARS_PRIVATE_SUBNET_CIDR_B//[$'\t\r\n ']}" >> $GITHUB_ENV
        env:
          VARS_CUSTOM_VPC_CIDR: ${{ vars.CUSTOM_VPC_CIDR }}
          VARS_PUBLIC_SUBNET_CIDR_A: ${{ vars.PUBLIC_SUBNET_CIDR_A }}
          VARS_PUBLIC_SUBNET_CIDR_B: ${{ vars.PUBLIC_SUBNET_CIDR_B }}
          VARS_PRIVATE_SUBNET_CIDR_A: ${{ vars.PRIVATE_SUBNET_CIDR_A }}
          VARS_PRIVATE_SUBNET_CIDR_B: ${{ vars.PRIVATE_SUBNET_CIDR_B }}

      # Step 3: Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # Step 4: Setup Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20.x
          cache: 'npm'
          cache-dependency-path: 'iac/package-lock.json'

      # Step 5: Install CDKTF
      - name: Install CDKTF
        run: npm install -g cdktf-cli@latest

      # Step 6: Install Terraform
      - name: Install Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: latest
          terraform_wrapper: false

      # Step 7A: Destroy existing infra - with ECR cleanup first
      - name: Destroy existing AWS Infrastructure
        continue-on-error: true
        run: |
          # First, delete all images from ECR repository
          echo "Cleaning up ECR repository..."
          REPO_ARN=$(aws ecr describe-repositories --repository-names ${{ env.APP_REPO_NAME }} --query 'repositories[0].repositoryArn' --output text 2>/dev/null || echo "")
          if [ -n "$REPO_ARN" ]; then
            echo "Found ECR repository, deleting images..."
            aws ecr batch-delete-image \
              --repository-name ${{ env.APP_REPO_NAME }} \
              --image-ids "$(aws ecr list-images --repository-name ${{ env.APP_REPO_NAME }} --query 'imageIds[*]' --output json)" \
              || echo "No images to delete or already deleted"
          else
            echo "ECR repository not found, skipping image cleanup"
          fi

          # Then destroy infrastructure
          echo "Destroying infrastructure..."
          cd iac
          npm ci
          cdktf get
          cdktf destroy --auto-approve || echo "No existing infra to destroy"
        env:
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          CUSTOM_VPC_CIDR: ${{ env.CUSTOM_VPC_CIDR }}
          PUBLIC_SUBNET_CIDR_A: ${{ env.PUBLIC_SUBNET_CIDR_A }}
          PUBLIC_SUBNET_CIDR_B: ${{ env.PUBLIC_SUBNET_CIDR_B }}
          PRIVATE_SUBNET_CIDR_A: ${{ env.PRIVATE_SUBNET_CIDR_A }}
          PRIVATE_SUBNET_CIDR_B: ${{ env.PRIVATE_SUBNET_CIDR_B }}
          AWS_REGION: ${{ env.AWS_REGION }}

      # Step 7B: Wait for AWS cleanup
      - name: Wait for AWS cleanup
        run: sleep 300

      # Step 8: Deploy AWS Infrastructure fresh
      - name: Deploy AWS Infrastructure
        run: |
          cd iac
          npm ci
          cdktf get
          cdktf deploy --auto-approve
        env:
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          CUSTOM_VPC_CIDR: ${{ env.CUSTOM_VPC_CIDR }}
          PUBLIC_SUBNET_CIDR_A: ${{ env.PUBLIC_SUBNET_CIDR_A }}
          PUBLIC_SUBNET_CIDR_B: ${{ env.PUBLIC_SUBNET_CIDR_B }}
          PRIVATE_SUBNET_CIDR_A: ${{ env.PRIVATE_SUBNET_CIDR_A }}
          PRIVATE_SUBNET_CIDR_B: ${{ env.PRIVATE_SUBNET_CIDR_B }}

      # Step 9: Verify Network Connectivity
      - name: Verify ECR Access
        run: |
          aws ec2 describe-nat-gateways --region $AWS_REGION
          aws ecr describe-repositories --repository-names $APP_REPO_NAME --region $AWS_REGION

      # Step 10: Wait for infrastructure stabilization
      - name: Wait for infrastructure stabilization
        run: sleep 60

      # Step 11: Login to ECR
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      # Step 12: Build Docker image from app/Dockerfile
      - name: Build Docker image
        run: |
          docker buildx build --platform linux/amd64 \
            -t ${{ steps.login-ecr.outputs.registry }}/${{ env.APP_REPO_NAME }}:${{ env.APP_IMAGE_TAG }} \
            ./app

      # Step 13: Push Docker image
      - name: Push Docker image
        run: |
          docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.APP_REPO_NAME }}:${{ env.APP_IMAGE_TAG }}

      # Step 14: Force ECS deployment with extended timeout
      - name: Force ECS deployment
        run: |
          aws ecs update-service \
            --cluster ${{ env.APP_CLUSTER_NAME }} \
            --service ${{ env.APP_CLUSTER_NAME }}-service \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}
          aws ecs wait services-stable \
            --cluster ${{ env.APP_CLUSTER_NAME }} \
            --services ${{ env.APP_CLUSTER_NAME }}-service \
            --region ${{ env.AWS_REGION }}
          echo "Waiting 120 seconds to ensure service stabilization..."
          sleep 120

      # Step 15: Get ALB DNS more reliably
      - name: Get ALB DNS
        id: alb-dns
        run: |
          echo "Trying terraform output..."
          cd iac
          if terraform output -raw albDnsName > /tmp/alb_dns 2>/dev/null; then
            echo "Terraform output worked."
          else
            echo "Terraform output failed, falling back to AWS CLI..."
            aws elbv2 describe-load-balancers \
              --names tv-devops-alb \
              --query 'LoadBalancers[0].DNSName' \
              --output text > /tmp/alb_dns
          fi
          cat /tmp/alb_dns
          echo "ALB_DNS=$(cat /tmp/alb_dns)" >> $GITHUB_ENV

      # Step 16: Test endpoint with retries
      - name: Test ALB endpoint
        run: |
          echo "Testing health endpoint: http://${ALB_DNS}/health"
          for i in {1..10}; do
            if curl -sSf http://${ALB_DNS}/health; then
              echo "Health check passed"
              exit 0
            fi
            echo "Waiting 15s before retry... ($i/10)"
            sleep 30
          done
          echo "ALB health endpoint failed after 10 attempts"
          exit 1
